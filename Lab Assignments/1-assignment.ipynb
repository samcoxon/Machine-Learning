{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "During this first assignment you will create your own dataset, implement and perform linear regression and investigate its results with different datasets.\n",
    "\n",
    "1. Create datasets, set noise, add outliers, create large/small set\n",
    "2. Perform Least squares with SK learn\n",
    "3. Implement least squares manually\n",
    "4. Bonus\n",
    "\n",
    "Publish your notebook to Machine Learning repository on Github.\n",
    "\n",
    "### Deadline 28 September 23:59\n",
    "\n",
    "Do not hand in any other files, the Notebook should contain all your answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the dataset\n",
    "\n",
    "In order to create the dataset we will use the [scikit-learn](http://scikit-learn.org/) toolkit (install first!). Specifically the [make_regression](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html) function, which generates a dataset that is a good target for regression.\n",
    "\n",
    "## Problem 1\n",
    "Create several different datasets. Vary their sizes, levels of noise and add some outliers.\n",
    "\n",
    "It is only necessary to create them (you can visualize them for yourself, but you don't need to hand this in). You are going to use them in the next problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "noise = 5 #Standard deviation of added Gaussian noise\n",
    "n_samples = 100 #Size of the dataset\n",
    "n_dimensions = 1 #We are doing univariate regression, so leave this at 1\n",
    "(x1,y1) = make_regression(n_samples=n_samples, n_features=n_dimensions, noise=noise)\n",
    "(x1_test,y1_test) = make_regression(n_samples=50, n_features=n_dimensions, noise=noise)\n",
    "plt.plot(x1,y1,'o')\n",
    "\n",
    "############### More DATASETS\n",
    "\n",
    "# (x2,y2) = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Linear Regression\n",
    "\n",
    "Scikit-learn has an implementation of [Linear Regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html). Below you see an example of how to use it.\n",
    "\n",
    "## Problem 2\n",
    "Use the scikit-learn method to fit your own datasets. What is the effect on the score of varying the amount of noise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#The regression object\n",
    "#this code constructs a local version of linear regression\n",
    "regr = LinearRegression()\n",
    "\n",
    "#Fit the regression object on the data\n",
    "regr.fit(x1,y1)\n",
    "\n",
    "#Print the score that the fit has\n",
    "print regr.score(x1_test,y1_test)\n",
    "\n",
    "#Plot the resulting line\n",
    "plt.plot(x1,regr.predict(x1))\n",
    "plt.plot(x1,y1,'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your analysis\n",
    "\n",
    "\n",
    "--Just write here--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Add a serious outlier and see what happens\n",
    "\n",
    "#Example of creating big outlier:\n",
    "x1[-1] = 20 #negative indices begin at the end. So this changes the last values of x1 and y1\n",
    "y1[-1] = -500\n",
    "\n",
    "#Create a plot that shows how the prediction can be very wrong in the presence of a serious outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Implement Linear regression\n",
    "\n",
    "In class you looked at performing regression using gradient descent. Now you are going to implement it.\n",
    "\n",
    "Make sure to comment your code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make a prediction function h\n",
    "def prediction_function(x,theta0,theta1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Use the output of that function to compute the cost function J:\n",
    "def cost_function(x_predict,y):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create a function that returns the gradient values, given h (x_predict), y and x:\n",
    "def compute_gradient(x_predict,y, x):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#These are some default parameters, see how playing with them affects the behavior\n",
    "alpha = 0.1\n",
    "theta0 = 0\n",
    "theta1 = 1\n",
    "x = x1\n",
    "y = y1\n",
    "iterations = 10\n",
    "#Fill in the stopcondition yourself\n",
    "stopcondition = \n",
    "\n",
    "i = 0\n",
    "cost = 10\n",
    "#Try to save the output of the cost function at each iteration and plot it at the end\n",
    "while (i < iterations) and (cost > stopcondition):\n",
    "    i = i +1\n",
    "    #Put everything together here\n",
    "    \n",
    "plt.plot(x,prediction_function(x,theta0,theta1))\n",
    "plt.plot(x,y,'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "\n",
    "Write a short analysis about the amount of iterations necessary to obtain a good result, the influence of the learning rate and the trend of the cost function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Problem: Implement Least Squares with closed form solution\n",
    "\n",
    "For the Least Squares method there is also a closed-form solution.\n",
    "\n",
    "$\\theta_1$ can be found by:\n",
    "$$ \\boldsymbol{\\hat\\theta_1} =( X ^TX)^{-1}X^{T}\\boldsymbol y $$\n",
    "\n",
    "You can leave $\\theta_0$ to be 0. Make a plot with your data as dots and your prediction as a line."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
